{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf1098e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_2956/1474702312.py, line 151)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_2956/1474702312.py\"\u001b[1;36m, line \u001b[1;32m151\u001b[0m\n\u001b[1;33m    ifnd = 'IF ' if not stack else ' AND '\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "def load_csv_to_header_data(filename):\n",
    "    path = os.path.normpath(os.getcwd() + filename)\n",
    "    print(path)\n",
    "    fs = csv.reader(open(path))\n",
    "    all_row = []\n",
    "    for r in fs:\n",
    "        all_row.append(r)\n",
    "    headers = all_row[0]\n",
    "    idx_to_name, name_to_idx = get_header_name_to_idx_maps(headers)\n",
    "    data = { 'header': headers,'rows': all_row[1:],'name_to_idx': name_to_idx,'idx_to_name':\n",
    "            idx_to_name}\n",
    "    return data\n",
    "\n",
    "def get_header_name_to_idx_maps(headers):\n",
    "    name_to_idx = {}\n",
    "    idx_to_name = {}\n",
    "    for i in range(0, len(headers)):\n",
    "        name_to_idx[headers[i]] = i\n",
    "        idx_to_name[i] = headers[i]\n",
    "    return idx_to_name, name_to_idx\n",
    "\n",
    "def project_columns(data, columns_to_project):\n",
    "    data_h = list(data['header'])\n",
    "    data_r = list(data['rows'])\n",
    "    all_cols = list(range(0,len(data_h)))\n",
    "    columns_to_project_ix = [data['name_to_idx'][name] for name in columns_to_project]\n",
    "    columns_to_remove = [cidx for cidx in all_cols if cidx not in columns_to_project_ix]\n",
    "    for delc in sorted(columns_to_remove, reverse=True):\n",
    "        del data_h[delc]\n",
    "        for r in data_r:\n",
    "            del r[delc]\n",
    "    idx_to_name, name_to_idx = get_header_name_to_idx_maps(data_h)\n",
    "    return {'header': data_h, 'rows': data_r,'name_to_idx': name_to_idx,'idx_to_name':\n",
    "    idx_to_name}\n",
    "\n",
    "def get_uniq_values(data):\n",
    "    idx_to_name = data['idx_to_name']\n",
    "    idxs = idx_to_name.keys()\n",
    "    val_map = {}\n",
    "    for idx in iter(idxs):\n",
    "        val_map[idx_to_name[idx]] = set()\n",
    "    for data_row in data['rows']:\n",
    "        for idx in idx_to_name.keys():\n",
    "            att_name = idx_to_name[idx]\n",
    "            val = data_row[idx]\n",
    "            if val not in val_map.values():\n",
    "                val_map[att_name].add(val)\n",
    "    return val_map\n",
    "def get_class_labels(data,target_attribute):\n",
    "    rows = data['rows']\n",
    "    col_idx = data['name_to_idx'][target_attribute]\n",
    "    labels = {}\n",
    "    for r in rows:\n",
    "        val = r[col_idx]\n",
    "        if val in labels:\n",
    "            labels[val] = labels[val] + 1\n",
    "        else:\n",
    "            labels[val] = 1\n",
    "        return labels\n",
    "    \n",
    "def entropy(n, labels):\n",
    "    ent = 0\n",
    "    for label in labels.keys():\n",
    "        p_x = labels[label] / n\n",
    "        ent += - p_x * math.log(p_x, 2)\n",
    "    return ent\n",
    "def partition_data(data, group_att):\n",
    "    partitions = {}\n",
    "    data_rows = data['rows']\n",
    "    partition_att_idx = data['name_to_idx'][group_att]\n",
    "    for row in data_rows:\n",
    "        row_val = row[partition_att_idx]\n",
    "        if row_val not in partitions.keys():\n",
    "            partitions[row_val] = {'name_to_idx': data['name_to_idx'],'idx_to_name':data['idx_to_name'],'rows': list()}\n",
    "            partitions[row_val]['rows'].append(row)\n",
    "    return partitions\n",
    "\n",
    "def avg_entropy_w_partitions(data, splitting_att, target_attribute): # find uniq values ofsplitting att\n",
    "    data_rows = data['rows']\n",
    "    n = len(data_rows)\n",
    "    partitions = partition_data(data, splitting_att)\n",
    "    avg_ent = 0\n",
    "    for partition_key in partitions.keys():\n",
    "        partitioned_data = partitions[partition_key]\n",
    "        partition_n = len(partitioned_data['rows'])\n",
    "        partition_labels = get_class_labels(partitioned_data, target_attribute)\n",
    "        partition_entropy = entropy(partition_n, partition_labels)\n",
    "        avg_ent += partition_n / n * partition_entropy\n",
    "    return avg_ent, partitions\n",
    "\n",
    "def most_common_label(labels):\n",
    "    mcl = max(labels, key=lambda k: labels[k])\n",
    "    return mcl\n",
    "def id3(data, uniqs, remaining_atts, target_attribute):\n",
    "    labels = get_class_labels(data, target_attribute)\n",
    "    node = {}\n",
    "    if len(labels.values()) == 1:\n",
    "        node['label'] = next(iter(labels.keys()))\n",
    "        return node\n",
    "    if len(remaining_atts) == 0:\n",
    "        node['label'] = most_common_label(labels)\n",
    "        return node\n",
    "    n = len(data['rows'])\n",
    "    ent = entropy(n, labels)\n",
    "    max_info_gain = None\n",
    "    max_info_gain_att = None\n",
    "    max_info_gain_partitions = None\n",
    "    for remaining_att in remaining_atts:\n",
    "        avg_ent, partitions = avg_entropy_w_partitions(data, remaining_att, target_attribute)\n",
    "        info_gain = ent - avg_ent\n",
    "        if max_info_gain is None or info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            max_info_gain_att = remaining_att\n",
    "            max_info_gain_partitions = partitions\n",
    "        if max_info_gain is None:\n",
    "            node['label'] = most_common_label(labels)\n",
    "            return node\n",
    "    node['attribute'] = max_info_gain_att\n",
    "    node['nodes'] = {}\n",
    "    remaining_atts_for_subtrees = set(remaining_atts)\n",
    "    remaining_atts_for_subtrees.discard(max_info_gain_att)\n",
    "    uniq_att_values = uniqs[max_info_gain_att]\n",
    "\n",
    "    for att_value in uniq_att_values:\n",
    "        if att_value not in max_info_gain_partitions.keys():\n",
    "            node['nodes'][att_value] = {'label': most_common_label(labels)}\n",
    "            continue\n",
    "        partition = max_info_gain_partitions[att_value]\n",
    "        node['nodes'][att_value] = id3(partition, uniqs, remaining_atts_for_subtrees,\n",
    "        target_attribute)\n",
    "    return node\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as myfile:\n",
    "        data = myfile.read().replace('\\n', '')\n",
    "        print(data)\n",
    "    return ast.literal_eval(data)\n",
    "\n",
    "def pretty_print_tree(root):\n",
    "    stack = []\n",
    "    rules = set()\n",
    "    def traverse(node, stack, rules):\n",
    "        if 'label' in node:\n",
    "            stack.append(' THEN ' + node['label'])\n",
    "            rules.add(''.join(stack))\n",
    "            stack.pop()\n",
    "        elif 'attribute' in node:\n",
    "        ifnd = 'IF ' if not stack else ' AND '\n",
    "        stack.append(ifnd + node['attribute'] + ' EQUALS ')\n",
    "        for subnode_key in node['nodes']:\n",
    "            stack.append(subnode_key)\n",
    "            traverse(node['nodes'][subnode_key], stack, rules)\n",
    "            stack.pop()\n",
    "        stack.pop()\n",
    "    traverse(root, stack, rules)\n",
    "    print(os.linesep.join(rules))\n",
    "\n",
    "    \n",
    "def main():\n",
    "    argv ='tennis.cfg'\n",
    "    print(\"Command line args are {}: \".format(argv))\n",
    "    config = load_config(argv)\n",
    "    print(config)\n",
    "    data = load_csv_to_header_data(config['data_file'])\n",
    "    data = project_columns(data, config['data_project_columns'])\n",
    "    target_attribute = config['target_attribute']\n",
    "    remaining_attributes = set(data['header'])\n",
    "    remaining_attributes.remove(target_attribute)\n",
    "    print(remaining_attributes)\n",
    "    uniqs = get_uniq_values(data)\n",
    "    root = id3(data, uniqs, remaining_attributes, target_attribute)pretty_print_tree(root)\n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2697cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
